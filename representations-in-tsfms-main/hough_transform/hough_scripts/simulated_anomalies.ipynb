{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "692f0e56",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import torch\n",
    "#import scripts.zero_shot_reconstruction as zs\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from gevar.data import WindTurbineDataset\n",
    "# from notebooks.helpers import get_all_cross_corr_features, compute_max_cross_corr\n",
    "# from notebooks.helpers import plot_mse_by_channel_with_total\n",
    "# from notebooks.helpers import apply_pca_to_frames\n",
    "from momentfm import MOMENTPipeline\n",
    "from scipy.stats import multivariate_normal\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b0440b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def create_data(n_examples, dimension, control_range, anomaly_value=1, noise_level = .25, control_noise_level = .01, seed=1):\n",
    "    torch.manual_seed(seed)\n",
    "    slices = [slice(i*dimension, (i+1)*dimension) for i in range(3)]\n",
    "    sig_len = dimension * 3\n",
    "    control_data = torch.zeros(n_examples, sig_len)\n",
    "    sensor_data = torch.zeros(n_examples, sig_len)\n",
    "    rand_v = torch.rand((n_examples,3)) * (control_range[1] - control_range[0]) + control_range[0]\n",
    "    for i in range(3):\n",
    "        control_data[:, slices[i]] = rand_v[:,i][:, None]\n",
    "\n",
    "    offsets = torch.rand(n_examples,)*6.28\n",
    "    for i in range(3):\n",
    "        sin_in = offsets[:, None] + anomaly_value*rand_v[:, i][:, None]*(torch.arange(dimension+1)[None, :].float() / dimension * 6.28*10)\n",
    "        sin_in = sin_in[:, 1:]\n",
    "        sin = torch.sin(sin_in)\n",
    "        sensor_data[:, slices[i]] = sin\n",
    "\n",
    "        cos = torch.cos(sin_in)\n",
    "        offsets = torch.atan2(sin[:,-1], cos[:,-1])\n",
    "        print(offsets)\n",
    "        offsets[offsets < 0] += 6.28  # Ensure offsets are in [0, 2*pi]\n",
    "\n",
    "        #sensor_data[:, slices[i]] = torch.sin(offsets[:, None] + control_data[:,slices[i]])\n",
    "        #offsets = torch.asin(sensor_data[:, (i+1)*dimension-1])\n",
    "        #is_down = sensor_data[:, (i+1)*dimension-1] - sensor_data[:, (i+1)*dimension-2] < 0\n",
    "        #offsets[is_down] = offsets[is_down] + 3.14\n",
    "       # print(offsets[0:4])\n",
    "\n",
    "    sensor_data += torch.randn_like(sensor_data) * noise_level\n",
    "    control_data += torch.randn_like(control_data) * control_noise_level\n",
    "    return control_data, sensor_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b896375",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "control_data_train, sensor_data_train = create_data(10000, 170, (0, 1), anomaly_value=1, seed=1)\n",
    "control_data_test, sensor_data_test = create_data(10000, 170, (0, 1), anomaly_value=1, seed=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1905d77",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1)\n",
    "ax[0].plot(control_data_train[10, :].numpy())\n",
    "ax[0].set_ylabel('Control Frequency')\n",
    "ax[1].plot(sensor_data_train[10, :].numpy())\n",
    "ax[1].set_ylabel('Sensor Frequency')\n",
    "ax[1].set_xlabel('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592eb397",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = MOMENTPipeline.from_pretrained(\n",
    "        \"AutonLab/MOMENT-1-base\", #(\"AutonLab/MOMENT-1-large\")\n",
    "        model_kwargs={\"task_name\": 'embedding'},\n",
    "    )\n",
    "embed_dim=512+256\n",
    "model.init()\n",
    "dir(model)\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ddbc3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def compute_embeddings(control, sensor, batch_size=512):\n",
    "    embeddings = torch.zeros(control.shape[0], embed_dim*2, device=device)\n",
    "    dataset = TensorDataset(control, sensor)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, (control_batch, sensor_batch) in enumerate(tqdm(dataloader)):\n",
    "            control_batch = control_batch.to(device)\n",
    "            sensor_batch = sensor_batch.to(device)\n",
    "            control_embeddings = model(x_enc=control_batch.unsqueeze(1)).embeddings\n",
    "            sensor_embeddings = model(x_enc=sensor_batch.unsqueeze(1)).embeddings\n",
    "            embeddings[i * batch_size:(i + 1) * batch_size, 0:embed_dim] = control_embeddings\n",
    "            embeddings[i * batch_size:(i + 1) * batch_size, embed_dim:] = sensor_embeddings\n",
    "\n",
    "    return embeddings.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ac8189",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_train = compute_embeddings(control_data_train, sensor_data_train)\n",
    "embeddings_test = compute_embeddings(control_data_test, sensor_data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f031cfef",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "anomaly_value = .1\n",
    "control_data_anomaly, sensor_data_anomaly = create_data(10000, 170, (0, 1), anomaly_value=anomaly_value, seed=3)\n",
    "embeddings_anomaly = compute_embeddings(control_data_anomaly, sensor_data_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f994f7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "data_train = torch.cat((control_data_train, sensor_data_train), dim=1)\n",
    "data_test = torch.cat((control_data_test, sensor_data_test), dim=1)\n",
    "data_anomaly = torch.cat((control_data_anomaly, sensor_data_anomaly), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdbe35d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "control_data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedabc93",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "mvn_data = multivariate_normal(mean=data_train.mean(axis=0), cov=np.cov(data_train.T))\n",
    "mvn_embed = multivariate_normal(mean=embeddings_train.mean(axis=0), cov=np.cov(embeddings_train.T))\n",
    "\n",
    "p_data_train = mvn_data.logpdf(data_train.numpy())\n",
    "p_data_test = mvn_data.logpdf(data_test.numpy())\n",
    "p_data_anomaly = mvn_data.logpdf(data_anomaly.numpy())\n",
    "\n",
    "p_embeddings_train = mvn_embed.logpdf(embeddings_train)\n",
    "p_embeddings_test = mvn_embed.logpdf(embeddings_test)\n",
    "p_embeddings_anomaly = mvn_embed.logpdf(embeddings_anomaly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c29213",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "plt.hist(p_data_train, bins=100, alpha=0.5, label='Train Data')\n",
    "plt.hist(p_data_test, bins=100, alpha=0.5, label='Test Data')\n",
    "plt.hist(p_data_anomaly, bins=100, alpha=0.5, label='Anomaly Data')\n",
    "plt.legend()\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Log Probability Distribution of Data\\n Anomaly Value: {anomaly_value}')\n",
    "plt.savefig(f'../../plots/p_data_{anomaly_value}.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306b0ff6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "_, bins, _ = plt.hist(p_embeddings_train, bins=100, alpha=0.5, label='Train Embeddings')\n",
    "plt.hist(p_embeddings_test, bins=bins, alpha=0.5, label='Test Embeddings')\n",
    "plt.hist(p_embeddings_anomaly, bins=bins, alpha=0.5, label='Anomaly Embeddings')\n",
    "plt.legend()\n",
    "plt.xlabel('Log Probability')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title(f'Log Probability Distribution of Embeddings\\n Anomaly Value: {anomaly_value}')\n",
    "plt.savefig(f'../../plots/p_embed_{anomaly_value}.png')\n",
    "#plt.xscale('log')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb9e536",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, thresholds = roc_curve(np.concatenate([np.zeros(len(p_embeddings_test)),\n",
    "                                                  np.ones(len(p_embeddings_anomaly))]),\n",
    "                                 np.concatenate([-p_embeddings_test, -p_embeddings_anomaly]))\n",
    "fpr_data, tpr_data, thresholds_data = roc_curve(np.concatenate([np.zeros(len(p_data_test)),\n",
    "                                                  np.ones(len(p_data_anomaly))]),\n",
    "                                 np.concatenate([-p_data_test, -p_data_anomaly]))\n",
    "plt.plot(fpr, tpr, label='Embeddings ROC (AUC = {:.2f})'.format(auc(fpr, tpr)))\n",
    "plt.plot(fpr_data, tpr_data, label='Data ROC (AUC = {:.2f})'.format(auc(fpr_data, tpr_data)))\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n",
    "plt.xlabel('False Anomaly Rate')\n",
    "plt.ylabel('True Anomaly Rate')\n",
    "plt.legend()\n",
    "plt.savefig(f'../../plots/roc_{anomaly_value}.png')\n",
    "\n",
    "plt.title(f'ROC Curve for Anomaly Detection \\n Anomaly Value: {anomaly_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2cd07",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pca_embed = PCA(n_components=embeddings_train.shape[1])\n",
    "pca_embed.fit(embeddings_train)\n",
    "pca_coeff_embed_test = pca_embed.transform(embeddings_test)\n",
    "pca_coeff_embed_anomaly = pca_embed.transform(embeddings_anomaly)\n",
    "\n",
    "for k in [0, 1, 2, 3, 5, 10, 20, 40, 80, 160, 300, 500]:\n",
    "    with_zeros_test = pca_coeff_embed_test.copy()\n",
    "    with_zeros_test[:, k:] = 0\n",
    "    pca_recon_embed_test = pca_embed.inverse_transform(with_zeros_test)\n",
    "\n",
    "    with_zeros_anomaly = pca_coeff_embed_anomaly.copy()\n",
    "    with_zeros_anomaly[:, k:] = 0\n",
    "    pca_recon_embed_anomaly = pca_embed.inverse_transform(with_zeros_anomaly)\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(np.concatenate([np.zeros(len(pca_recon_embed_test)),\n",
    "                                                    np.ones(len(pca_recon_embed_anomaly))]),\n",
    "                                    np.concatenate([np.linalg.norm(pca_recon_embed_test, axis=1),\n",
    "                                                    np.linalg.norm(pca_recon_embed_anomaly, axis=1)]))\n",
    "\n",
    "    plt.plot(fpr, tpr, label='PCA Embed k={} ROC (AUC = {:.2f})'.format(k, auc(fpr, tpr)))\n",
    "    plt.title(f'PCA Embedding ROC Curve \\n Anomaly Value: {anomaly_value}')\n",
    "    plt.savefig(f'../../plots/pca_embed_roc_{anomaly_value}.png')\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4dfd72",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
